\documentclass[11pt, oneside]{article}
\usepackage{lmodern} % Use scalable fonts to avoid font substitution warnings
\usepackage{tikz-cd} % Commuting diagrams
\usepackage[a4paper, margin=1in]{geometry} % Adjust margins
\usepackage[noxy, goodsyntax]{virginialake} % Typesetting derivations
\usepackage{xcolor}
\usepackage{amsthm} % Theorem environments
\usepackage{titlesec}
\usepackage{amsmath} % Symbols
\usepackage{graphicx} % Better figures
\usepackage{caption} % Figure captions
\usepackage{mathtools} % '\denote' command
\usepackage{stmaryrd} % Double brackets
\usepackage{cancel} % Negataing coherence relations
\usepackage{bm} % Bold maths expressions
\usepackage{changepage} % Indenting sections in proofs
\usepackage{tocloft}
\usepackage{tikz} % Structure bracket heirarchy

\usetikzlibrary{arrows.meta, positioning, decorations.markings}
\setlength{\cftbeforesecskip}{11pt}  % Adjusts spacing before section entries
% Remove paragraph indentation
\setlength{\parindent}{0pt}
% Add space between paragraphs
\setlength{\parskip}{1em}

\titleformat{\section}[block]{\normalfont\bfseries\fontsize{1.3em}{1.3em}\selectfont}{\thesection}{1em}{}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section] 
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma} 
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem*{remark}{Remark}
\newtheorem{example}[theorem]{Example}
\usepackage{etoolbox}
\AtBeginEnvironment{proof}{\vspace{-25pt}} % Adjust as needed
\hyphenation{Straß-burger}

\let\originaldagger\dagger
\renewcommand{\dag}{\mathord{\originaldagger}}
\newcommand{\hash}{\mathord{\raisebox{0.3ex}{\scalebox{0.7}{$\mathstrut \# $}}}}
\DeclarePairedDelimiter\denote\llbracket\rrbracket

\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\lp}{\llparenthesis}
\newcommand{\rp}{\rrparenthesis}
\newcommand{\sSys}{{\mathsf{TREL}}}%
\newcommand{\cohs}{{\mathsf{COHS}}}
\newcommand{\coh}[1][]{\mathrel{\vcenter{\offinterlineskip\hbox{$\frown$}\vskip0.2ex\hbox{$\smile$}}_{\ifx\\#1\\\else#1\fi}}}
\newcommand{\incoh}[1][]{\mathrel{\vcenter{\offinterlineskip\hbox{$\smile$}\vskip0.2ex\hbox{$\frown$}}_{\ifx\\#1\\\else#1\fi}}}
\newcommand{\notcoh}[1][]{\cancel{\coh}_{\ifx\\#1\\\else#1\fi}}
\newcommand{\scoh}[1][]{\mathrel{\frown}_{\ifx\\#1\\\else#1\fi}}
\newcommand{\comp}{\mathbin{\circ}}
\newcommand{\unit}{\circ}

\title{A Deep Inference Model of State}
\author{Jamie Brine}

\begin{document}

\maketitle

\begin{abstract}
    Made a thing, it did a thing, very happy.
\end{abstract}

\newpage
\tableofcontents

\newpage
\section{Introduction}
\subsection{Modelling Computation}
Proof theorists have developed countless proof systems as mechanisms with which to not only give proofs, but also model computation.
Each system has its own grammar and rules, and can capture a particular aspect of how a computer programs execute.
They may choose to model resource sensitivity in producer/consumer relationships \cite{joshi1996partial}, shared-memory parallel code \cite{woodcock2002unifying}, or compiler optimisation techniques \cite{tate2010generating}.

The key idea underpinning these models is the Curry-Howard correspondence.
This was first proposed by Haskell Curry in the 1940s, then explicitly formulated by William Alvin Howard in the 1960s.
A typeset version of Howard's original hand-written notes have been published \cite{howard1980formulae};
for a more modern and detailed explanation, the reader is referred to a Master's thesis by Husna Farooqui \cite{farooqui2021curry}.
The correspondence can be distilled to the following phrase:

\begin{center}
"Propositions are types, and proofs are programs"
\end{center}

More formally, it provides a framework in which constructing a proof corresponds writing a program, and normalisation of that proof corresponds to the program's execution.
The return type of the program is precisely the type that the conclusion of the proof represents.
This connection allows for programs to studied through the lens of logic, particularly with respect to properties like correctness and termination;
if a proof is valid in the underlying system, so too is the program it corresponds to.

\subsection{Deep Inference}
This foundational idea has been extended and enriched with the advent of deep inference, a relatively recent development in proof theory.
Deep inference is a methodology that contrasts with traditional approaches such as natural deduction and the sequent calculus, in which inference rules are restricted to apply only at the outermost (or top-level) structure of formulae.
In contrast, deep inference systems permit inference rules to be applied at any depth within a formula's structure.
This increased freedom introduces new possibilities for proof compression, locality, and symmetry.
In turn, the types and programs that can be encoded by these systems are more expressive and finely controlled, allowing for richer representations of computational processes and more efficient proof search.

This flexibility is exemplified in deep inference systems such as BV and NEL.
BV \cite{bruscoli2002purely} is a system based on multiplicative linear logic, where a self-dual non-commutative connective is treated using deep inference principles.
NEL \cite{guglielmi2002non} further extends these ideas by incorporating duplicable structures.
For a comprehensive explanation of deep inference, and how its relatively subtle differences to classical proof techniques allow for staggering improvements in efficiency, the reader is referred to Guglielmi \cite{guglielmi2015deep}.
His pioneering work throughout the 2000s contributed greatly to the development of the methodology.

\subsection{How to Model State?}
Simply put, the state of a program refers to the set of values or conditions that exist at any given point during its execution, encompassing variables, data structures, and other program-related information that influence its behavior.
modelling state is essential for understanding how programs evolve over time, tracking the effects of operations, and ensuring correctness in the program's execution.

Uday Reddy proposed the idea of modelling state with an extension of linear logic.
In a 1993 paper \cite{reddy1993all}, he proposes a logical system which extends the well studied system of linear logic with two new operators:
a connective "before" which is used to impose order on terms in a proposition, and a regenerative storage operator "dagger" which allows these ordered terms to produce "traces".
He explains that "a trace denotes the information extracted from a storage object in one particular execution of a program".
He calls this system the Linear Logic Model of State.

Reddy also gives semantics to his system using a coherence space model.
Semantic models of logical systems are valuable, as their category-theoretic nature allows for a more abstract and structured understanding of the relationships between logical formulas and their proofs, enabling the exploration of proofs as morphisms within a category.
This provides powerful tools for reasoning about logical systems, facilitating the comparison of different proof systems and allowing for the transfer of results across various areas of logic and computation.

\subsection{Motivation}
In a preliminary version of this paper \cite{reddy1993linear}, Reddy acknowledges that "for the regenerative type system, we need a non-commutative tensor product which has all the properties of tensor except for the commutative property".
This motivates a natural continuation of his work: can we add non-commutativity to the Linear Logic Model of State in order to more richly model program state?

In this paper, we present the system $\sSys$ ("Trace-Respecting Exponential Linear logic"), with which we attempt to answer this question.
It is a deep inference system similar to those mentioned previously, which offers a more flexible framework for reasoning about non-commutative structures within logic.
This is particularly useful for modelling complex interactions within program state, where the order of operations may be significant.

We give a full coherence space model for the system, which allows us to study it mathematically and prove a number of useful facts about its nature.
The model is an important tool which helps guide the design of the logic, ensuring that the rules we introduce behave in the way we require them to.
By considering all decisions from both logical and categorical perspectives, we ensure the system remains both sound and semantically well-motivated.

Crucially, we aim to show that the categorical model of any proof is a dinatural transformation.
The equivalent notion in the logic is that no matter which pair of objects are being related, the structure of the relationship remains invariant, providing a deeper understanding of how proof transformations preserve logical properties.
While we do not give a direct argument for this property in this paper, we conjecture that it is indeed true, giving a sequence of supporting lemmas.
We also show contrasting cases from other systems which do not enjoy this property, highlighting the specific features of our logic that we believe prevent such failures.
This is an important step in proving the consistency of the logic.

\newpage
\section{System $\sSys$}

This system is a modification of $\NEL$, first proposed by Guglielmi and Straßburger in 2002 \cite{guglielmi2002non}.
The main difference between $\NEL$ and $\sSys$ is that the $!$ and $?$ structures, which are referred to collectively as the \textit{exponentials}, have been replaced by $\dag$ and $\hash$.
These new exponentials can be considered ordered, which is reflected in the modified $\bD$ and $\bU$ rules governing their regeneration.

\subsection{Structures and Equivalence}

\begin{definition}
\textit{Structures} in $\sSys$, denoted $R$,$S$,$T$,$V$.., are defined by the following grammar:

\[R ::= \unit \,|\, a \,|\, \overline{R} \,|\, \dag R \,|\, \hash R \,|\, (R,..,R) \,|\, \la R;..;R\ra \,|\, [R,..,R]\]

where
\begin{itemize}
\item $\unit$ is the \textit{unit}, which is common to all structures and also self dual; this can be thought of as an empty structure
\item $a$ is an \textit{atom}, of which there are countably many
\item $\overline{R}$ is the \textit{dual} of $R$
\item $\dag R$ and $\hash R$ are the \textit{dagger} and \textit{hash} of $R$ respectively
\item $(R,..,R)$, $\la R;..;R\ra$, and $[R,..,R]$ are \textit{copar}, \textit{seq}, and \textit{par} structures; they are considered \textit{proper} if they contain at least two elements
\end{itemize}
\end{definition}

\begin{definition}
A structure with an empty hole, $S\{\,\,\}$, is called a \textit{context}.
We say $R$ is a \textit{substructure} of $S\{R\}$.
If structural parentheses fill the hole exactly, the curly braces will be omitted, so for example $S\{[R,T]\}$ becomes $S[R,T]$.
\end{definition}

\begin{definition}
Structures $R$ and $S$ are considered \textit{equivalent} modulo the relation $=$, which is the smallest congruence defined by the equations in Figure \ref{fig:equivalence}.
\end{definition}

\begin{figure}[ht!]
    \centering
    \setlength{\fboxsep}{5pt} % Padding inside the box
    \setlength{\fboxrule}{0.5pt} % Thickness of the box border
    \fbox{%
        \begin{minipage}{0.95\textwidth} % Outer box spanning full width
            \begin{minipage}{0.45\textwidth} % First column

                \begin{align*}
                    \textbf{Assoc}&\textbf{iativity} \\
                    (R,(T)) &= (R,T) \\
                    \la R;\la T\ra; U\ra &= \la R;T;U\ra \\
                    [R,[T]] &= [R,T]
                \end{align*}
                \begin{align*}
                    \textbf{Comm}&\textbf{utativity}\\
                    (R, T) &= (T, R) \\
                    [R, T] &= [T, R]
                \end{align*}
                \begin{align*}
                    \textbf{U}&\textbf{nit} \\
                    (R,T,\unit) &= (R,T) \\
                    \la R;T;\unit\ra &= \la R;T\ra \\
                    \la\unit;R;T\ra &= \la R;T\ra \\
                    [R,T,\unit] &= [R,T] \\
                \end{align*}
            \end{minipage}
            \hfill
            \begin{minipage}{0.45\textwidth}
                \begin{align*}
                    \textbf{Sing}&\textbf{leton} \\
                    (R) = \la R\ra &= [R] = R
                \end{align*}
                \begin{align*}
                    \textbf{D}&\textbf{ual} \\
                    \overline{\unit} &= \unit \\
                    \overline{(R,T)} &= [\overline{R},\overline{T}] \\
                    \overline{\la R;T\ra} &= \la \overline{R};\overline{T}\ra \\
                    \overline{[R,T]} &= (\overline{R},\overline{T}) \\
                    \overline{\dag R} &= \hash\overline{R} \\
                    \overline{\hash R} &= \dag \overline{R} \\
                    \overline{\overline{R}} &= R
                \end{align*}
                \begin{align*}
                    \textbf{Contextu}&\textbf{al Closure} \\
                    \text{if }S\{R\} &= S\{T\} \text{,} \\
                    \text{then }R&=T
                \end{align*}
            \end{minipage}
        \end{minipage}
    }
    \caption{Syntactic Equivalence}
    \label{fig:equivalence}
\end{figure}

\subsection{Rewrite Rules, Derivations, and Proofs}

We describe how structures can be modified using a set of rules, and how these rules can be chained together to form longer derivations.
In particular, we are interested in those derivations which begin with an empty premise, which we will call proofs. 

\begin{definition}
A \textit{rewrite rule} is a rule $\rho$ with \textit{premise} T and \textit{conclusion} R, denoted $\vlinf{\rho}{}{R}{T}$.
All of the rewrite rules in $\sSys$ are given in Figure \ref{fig:rules}.
\end{definition}

\begin{remark}
    As $\sSys$ is a deep inference system, a rewrite rule can be applied at arbitrary depth within any structure.
\end{remark}
    
\begin{figure}[ht!]
    \centering
    \setlength{\fboxsep}{5pt} % Padding inside the box
    \setlength{\fboxrule}{0.5pt} % Thickness of the box border
    \fbox{%
        \begin{minipage}{0.95\textwidth} % Outer box spanning full width
            \begin{minipage}{0.3\textwidth} % First column
                \centering
                \[
                \vlderivation{
                    \vlin{\aiD}{}{S[a,\overline{a}]}
                    {\vlhy{S\{\unit\}}}
                    }
                \] 
                \\
                \[
                \vlderivation{
                    \vlin{\aiU}{}{S\{\unit\}}
                    {\vlhy{S(a,\overline{a})}}
                    }  
                \]
                \\
                \[
                \vlderivation{
                    \vlin{\wD}{}{S\{\hash R\}}
                    {\vlhy{S\{\unit\}}}
                    }
                \] 
                \\
                \[
                \vlderivation{
                    \vlin{\wU}{}{S\{\unit\}}
                    {\vlhy{S\{\dag R\}}}
                    }  
                \]
                \\
                \vspace{0.5em}
            \end{minipage}
            \hfill
            \begin{minipage}{0.3\textwidth}
                \centering
                \[
                \vlderivation{
                    \vlin{\dD}{}{S\{\dag\unit\}}
                    {\vlhy{S\{\unit\}}}
                    }
                \]
                \\
                \[
                \vlderivation{
                    \vlin{\dU}{}{S\{\unit\}}
                    {\vlhy{S\{\hash\unit\}}}
                    }
                \]
                \\
                \[
                \vlderivation{
                    \vlin{\bD}{}{S\{\hash R\}}
                    {\vlhy{S\la R;\hash R\ra}}
                    }  
                \]
                \\
                \[
                \vlderivation{
                    \vlin{\bU}{}{S\la R;\dag R\ra}
                    {\vlhy{S\{\dag R\}}}
                    }  
                \]
                \\
                \[
                \vlderivation{
                    \vlin{\sw}{}{S[(R,U),T]}
                    {\vlhy{S([R,T],U)}}
                    }  
                \]
                \\
                \vspace{0.5em}
            \end{minipage}
            \begin{minipage}{0.35\textwidth}
                \centering
                \[
                \vlderivation{
                    \vlin{\qD}{}{S[\la R;U\ra,\la T;V\ra]}
                    {\vlhy{S\la[R,T];[U,V]\ra}}
                    }  
                \]
                \\
                \[
                \vlderivation{
                    \vlin{\qU}{}{S\la(R,U);(T,V)\ra}
                    {\vlhy{S(\la R;T\ra,\la U;V\ra)}}
                    }
                \]
                \\
                \[
                \vlderivation{
                    \vlin{\pD}{}{S[\dag R, \hash T]}
                    {\vlhy{S\{\dag[R,T]\}}}
                    }
                \]
                \\
                \[
                \vlderivation{
                    \vlin{\pU}{}{S\{\hash(R,S)\}}
                    {\vlhy{S(\hash R,\dag S)}}
                    }
                \] 
                \\
                \vspace{0.5em}
            \end{minipage}
        \end{minipage}
    }
    \caption{Rewrite Rules for System $\sSys$}
    \label{fig:rules}
\end{figure}

Particular emphasis is placed on the $\bU$ and $\bD$ rules.
These rules exist in $\NEL$, but in a slightly different form, as shown in Figure \ref{fig:nel-vs-trel-rules}.
In $\sSys$, the duplicated version of a structure (in Reddy's terms, the "trace") that is produced by an application of $\bU$ is placed into a seq structure.
This means that when repeatedly producing traces of the same structure, there is an order imposed on them; this matches our intuition of how programs execute, where each successive execution builds upon the previous one in a well-defined sequence, preserving the causal relationships between computational steps.

\begin{figure}[ht]
    \centering
    \setlength{\tabcolsep}{2em} % spacing between columns
    \renewcommand{\arraystretch}{1.5} % vertical spacing between rows
    \begin{tabular}{c c}
        $\NEL$: & $\sSys$: \\
        $\vlderivation{
            \vlin{\bU}{}{S(R,!R)}
            {\vlhy{S\{!R\}}}
        }$ 
        &
        $\vlderivation{ 
            \vlin{\bU}{}{S\la R;\dag R\ra}
            {\vlhy{S\{\dag R\}}}
        } $
        \\\\
        $\vlderivation{ 
            \vlin{\bD}{}{S\{?R\}}
            {\vlhy{S[R,?R]}}
        }$
        &
        $\vlderivation{ 
            \vlin{\bD}{}{S\{\hash R\}}
            {\vlhy{S\la R;\hash R\ra}}
        }$
    \end{tabular}
    \caption{Comparison of the $\bU$ and $\bD$ rules in $\NEL$ (left) and $\sSys$ (right).}
    \label{fig:nel-vs-trel-rules}
\end{figure}

\begin{definition}
A \textit{derivation} $\Delta$ from $R$ to $T$ is a finite chain of rewrites with premise $R$ and conclusion $T$, denoted $\vlderivation{\vlde{\Delta}{}{T}{\vlhy{R}}}$.
A derivation whose premise is $\unit$ is called a \textit{proof}, to which we can add a topmost instance of the \textit{axiom} rule $\vlderivation{\vlin{\ax}{}{\unit}{\vlhy{}}}$;
these are denoted $\vlderivation{\vlproof{\Delta}{}{T}}$.
\end{definition}

\begin{remark}
Throughout this paper, we will state many results about derivations.
It is often the case that the corresponding result about proofs is in fact more useful to us in the context of modelling state, but we choose to give the more general result in most cases.
\end{remark}

\begin{proposition}\label{prop:DerivationToProof}
If $\vlderivation{\vlde{\Gamma}{}{T}{\vlhy{R}}}$ is a derivation, then there exists a proof $\vlderivation{\vlproof{\Delta}{}{[\overline{R},T]}}$.
\end{proposition}

\begin{proof}
In order to prove this, we use a generalised version of $\aiD$, which we call $\iD$:
\[
\vlderivation{
    \vlin{\iD}{}{S[R,\overline{R}]}
    {\vlhy{S\{\unit\}}}
    }
\] 

This rule can introduce any dual pair of structures, as opposed to $\aiD$ which strictly introduces atoms.
$\iD$ is adimissible in $\sSys$; any proof which uses it can be transformed into an equivalent (albeit more convoluted) one whose atoms are introduced sequentially with $\aiD$ (a key feature of deep inference) \cite{bruscoli2002purely}.
We thus need only to wrap the existing proof in the context $[\overline{R},\{\quad\}]$:

\[
\vlderivation{
    \vlde{[\overline{R},\Gamma]}{}{[\overline{R},T]}
    {\vlin{\iD}{}{[\overline{R},R]}{\vlhy{\unit}}}
}
\]


\end{proof}

\begin{example}\label{example:DerivationExample}
We give a derivation where, when read top down, the substructure on which the rule is being applied is bolded.
Note that this is not the simplest derivation from this premise to this conclusion, but has been chosen to demonstrate applying the rules at different levels within the structure.

\[
\vlderivation{
\vlin{\bD}{}{[\la R;\dag R\ra,\hash T]}{
\vlin{\qD}{}{[\la R,\dag R\ra,\bm{\la T;\hash T\ra}]}{
\vlin{\pD}{}{\bm{\la [R,T];[\dag R,\hash T]\ra}}{ 
\vlin{\bU}{}{\la [R,T];\bm{\dag[R,T]}\ra}{
\vlhy{\bm{\dag [R,T]}}
}}}}}
\]

\end{example}

\begin{example}
Negating the premise of the derivation from Example \ref{example:DerivationExample}, and then use the equivalence relation defined in Figure \ref{fig:equivalence} to push negation to the level of atoms, we get the following:
$$\overline{\dag [R,T]} = \hash \overline{[R,T]} = \hash (\overline{R},\overline{T})$$
Using Proposition \ref{prop:DerivationToProof}, we can hence guarantee that it is possible to construct the following proof:

\[
\vlproof{\Gamma}{}{
[\hash (\overline{R},\overline{T}),\la R;\dag R\ra,\hash T]}
\]
\end{example}

\newpage
\section{Coherence Space Semantics}

We give denotational semantics to system $\sSys$ using a coherence space model.
Broadly speaking, the aim of this model of the system is to give a representation of proofs of some structure $A$ as \textit{cliques} of the corresponding coherence space $\denote{A}$.

One of the advantages of doing so is that it allows us to derive properties about the logical system by working with purely categorical constructs.
Some desirable results may be difficult to prove using the logic of the system alone, but much simpler when we work with only the model.

\begin{remark}
We will give the semantics for $\sSys$ in terms of only binary versions of the connectives copar, seq, and par.
For example, instead of working with an arbitrary copar structure $(R_1,..,R_n)$, we will only consider the simpler case $(R,T)$, and instead rely on the associative property to inductively construct more complex structures.
\end{remark}

\subsection{Introduction to Coherence Spaces}
The idea of coherence spaces was first proposed by Jean-Yves Girard as a model for linear logic \cite{girard1987linear}, and has since been adapted by a range of researchers to model their own systems.
Most notably, Uday Reddy extended linear logic with an operator representing one-way communication \cite{reddy1993all}, and gave a coherence space semantics on which much of this work has been based.

We introduce the following definitions which will be used in defining our model.
For a more structured, category theoretic introduction to coherence spaces, the reader is referred to Paul-André Melliès' lecture notes \cite{mellies2000survival}.

\begin{definition}
    A \textit{coherence space} is a pair $(|A|,\coh[A])$, where $|A|$ is some underlying set and $\coh[A]$ is the \textit{coherence relation} defined on that set.
    The relation is symmetric and reflexive but not necessarily transitive.
    We also define a strictly irreflexive version $\scoh[A]$ which we call \textit{strict coherence}, such that $a\scoh[A]a' \iff a\coh[A]a'$ and $a\not=a'$
\end{definition}

\begin{definition}
    We say $a$ and $a'$ are \textit{incoherent}, written $a \incoh[A] a'$, if either $a \notcoh[A] a'$ or $a=a'$
\end{definition}

\begin{remark}
    We will often refer to the coherence space $(|A|,\coh[A])$ as simply $A$ when appropriate.
    Similarly, we will often write $\coh$ or $\scoh$ without the subscript when the coherence space is obvious from the context.
\end{remark}

\begin{definition}
    A \textit{clique} of a coherence space $A$ is some $C \subseteq |A|$, whose elements are all pairwise coherent.
\end{definition}

\begin{definition}
    A \textit{linear map} between coherence spaces $A$ and $B$ is some relation $f$ on $|A|$ and $|B|$,
    such that if $f$ relates $a$ to $b$, and also relates $a'$ to $b'$, we have that
    \begin{align*}
        a \coh[A] a' &\implies b \coh[B] b' \\
        a \scoh[A] a' &\implies b \scoh[B] b'
    \end{align*}

    We write $f:A\multimap B$, and use the notation $\lp a,b\rp\in f$ to mean "$f$ relates $a$ to $b$".
\end{definition}

\begin{definition}
    For linear maps $f:A\multimap B$ and $g:B\multimap C$, we define the \textit{composition} $g\comp f:A\multimap C$ by:
    $$g\comp f = \{\lp a,c\rp:\exists b\in|B|\text{ such that }\lp a,b\rp\in f, \lp b,c\rp\in g\}$$
\end{definition}

Armed with these definitions, we can begin to construct a semantic model of the system $\sSys$.
We will define a category whose morphisms are precisely these linear maps, and show that we can interpret structures as its objects.

\subsection{A Model for Structures of $\sSys$}

For each structure $x$ in the grammar of $\sSys$, we would like to define some semantic model $\denote{x}$ to represent it.
Thus, we can inductively define the semantics of an arbitrarily complex structure, starting by translating the atoms and then working outwards towards the outermost connective.
Here we will state the semantics that we would like for each structure, then, throughout the rest of this section, unpack and justify each definition.

\begin{remark}
    Throughout this section, for any coherence space $A$ we will only define $\coh[A]$.
    Deriving $\scoh[A]$ and $\incoh[A]$ is a simple exercise in applying the definitions of a coherence space, and thus is left to the reader.
\end{remark}

\begin{itemize}

\item
\textbf{Unit}: $\denote{\unit} = (\{*\},\{(*,*)\})$, a trivial coherence space whose underlying set is a singleton, with that single element related to itself.
Notice that $* \incoh[] *$ as the relation is strictly irreflexive, so $\scoh[\denote{\unit}]=\emptyset$.

\item
\textbf{Atom}: For each atom $a,b,..,z$ in a structure, we are able to choose any coherence space $A,B,..,Z$ to be the model $\denote{a},\denote{b},..,\denote{z}$.
For example, an atom $b$ representing the base type of booleans may have the semantics $\denote{b} = (\{\top,\bot\},\{(\top,\top),(\bot,\bot)\})$.

\item
\textbf{Dual}: $\denote{\overline{R}}=(|\denote{R}|,\incoh[\denote{R}])$.

\item
\textbf{Copar}: $\denote{(R,T)} = (\denote{R}\times\denote{T},\coh[\denote{(R,T)}])$,
such that:
$$(r_1,t_1)\coh(r_2,t_2)\iff r_1\coh[\denote{R}]r_2 \text{ and } t_1\coh[\denote{T}]t_2$$

\item
\textbf{Seq}: $\denote{\la R;T\ra} = (\denote{R}\times\denote{T},\coh[\denote{\la R;T\ra}])$, such that:
$$(r_1,t_1)\coh(r_2,t_2) \iff r_1\scoh[\denote{R}]r_2 \text{ or } (r_1 = r_2 \text{ and } t_1\coh[\denote{T}]t_2)$$

\item
\textbf{Par}: $\denote{[R,T]} = (\denote{R}\times\denote{T},\coh[\denote{[R,T]}])$, such that:
$$(r_1,t_1)\coh(r_2,t_2) \iff r_1\scoh[\denote{R}]r_2 \text{ or } t_1\scoh[\denote{T}]t_2 \text{ or } (r_1,t_1)=(r_2,t_2)$$

\item
\textbf{Dagger}: $\denote{\dag R} = (\denote{R}^*, \coh[\denote{\dag R}])$, such that:
$$r_1...r_m \coh r'_1...r'_n \iff \text{one of:}$$

\begin{itemize}
    \item
    $\exists 1\leq l \leq \min(m,n) \text{ s.t. } r_i=r'_i \enspace\forall i<l$, and $r_l \scoh[\denote{R}] r'_l$

    \item
    $r_i = r'_i \enspace\forall i\le\min(m,n)$
\end{itemize}

\item
\textbf{Hash}: $\denote{\hash R} = (\denote{R}^*, \coh[\denote{\hash R}])$, such that:
$$r_1...r_m \coh r'_1...r'_n \iff \text{one of:}$$

\begin{itemize}
    \item
    $\exists 1\leq l \leq \min(m,n) \text{ s.t. } r_i=r'_i \enspace\forall i<l$, and $r_l \scoh[\denote{R}] r'_l$

    \item
    $r_1...r_m = r'_1...r'_n$
\end{itemize}

\end{itemize}

\begin{remark}
    Later, structures will be interpreted as functors, with atoms acting as their inputs, so each structure can be seen as a kind of variable type.
\end{remark}

\subsection{Connectives are Functors}

We will now take a step back from modelling the system $\sSys$, and view the coherence space model from a purely categorical perspective.
For the rest of this section, we abstract out the underlying structure of any given coherence space, and instead consider how rewrite rules and connectives behave when applied to arbitrary ones.

We require that connectives in our model behave nicely when working in the category of coherence spaces.
We will briefly define this category, and then show that we can model each of the unary and binary connectives as functors.

Modelling connectives as functors allows rewrite rules to be applied within arbitrary contexts, by composing the rule's model with the functor representing the context.
This abstraction simplifies deep inference by making rule application uniform and modular, ensuring necessary properties are preserved at all levels of nesting.
Contexts can be constructed compositionally, providing a scalable and elegant framework for handling rules in arbitrary settings.

\begin{definition}
    The \textit{category of coherence spaces} is written $\cohs$, with coherence spaces as objects and linear maps between them as morphisms.
\end{definition}

\begin{remark}
In order to prove that the some functor $F:\cohs\to\cohs$ preserves coherence of some map $f:A\multimap B$, we will show 2 things:
\begin{enumerate}
    \item
    For $a\scoh[FA]a'$, and pairs $\lp a,b\rp,\lp a',b'\rp\in Ff$, we have that $b\scoh[FB]b'$
    \item 
    For pairs $\lp a,b\rp,\lp a,b'\rp\in Ff$, we have that $b\coh[FB]b'$
\end{enumerate}
(1) directly shows preservation of strict coherence. As strict coherence is a stronger condition than coherence, it also shows preservation of coherence in all cases aside from that where $a=a'$;
(2) verifies this case directly.
\end{remark}

\subsubsection{Copar}
\begin{definition}
    Let $(\_,\_):\cohs\times\cohs\to\cohs$ be defined as follows:
    \begin{itemize}
        \item
        For $R,T\in Ob(\cohs)$, $(R,T) \coloneqq (R\times T,\coh[(R,T)])$ such that:
        $$(r,t)\coh[(R,T)](r',t')\iff r\coh[R]r'\text{ and }t\coh[T]t'$$

        \item
        For $f:R\multimap T$ and $g:U\multimap V$, 
        $(f,g):(R,U)\multimap(T,V)$ is defined as follows:
        $$(f,g)=\{\lp(r,u),(t,v)\rp:\lp r,t\rp\in f,\lp u,v\rp\in g\}$$
    \end{itemize}
\end{definition}

\begin{lemma}\label{lem:CoparIsFunctor}
    $(\_,\_)$ is a functor.
\end{lemma}

\begin{proof}

    $(\_,\_)$ preserves coherence:
    \begin{adjustwidth}{1.5em}{}
        Define $f:R\multimap T$, $g:U\multimap V$.

        First assume that $(r,u)\scoh[(R,U)](r',u')$, and consider pairs $\lp(r,u),(t,v)\rp$, $\lp(r',u'),(t',v')\rp\in(f,g)$.
        Without loss of generality, assume that $r\scoh[R]r'$ and $u\coh[U]u'$.
        Linearity of $f$ and $g$ implies that $t\scoh[T]t'$ and $v\coh[V]v'$.
        This gives us $(t,v)\coh[(T,V)](t',v')$, and as $t\neq t'$ we find that the coherence is strict as required.

        Now consider pairs $\lp(r,u),(t,v)\rp,\lp(r,u),(t',v')\rp\in(f,g)$.
        Linearity of $f$ and $g$ implies that $t\coh[T]t'$ and $v\coh[V]v'$.
        This gives us $(t,v)\coh[(T,V)](t',v')$ as required.

    \end{adjustwidth}

    $(\_,\_)$ preserves identity:
    \begin{align*}
        (id_R,id_T) &= \{
            \lp(r,t),(r,t)\rp:\lp r,r\rp\in id_R,\lp t,t\rp\in id_T
        \} \\
        &= \{\lp(r,t),(r,t)\rp:r\in |R|,t\in |T|\} \\
        &= \{\lp(r,t),(r,t)\rp:(r,t)\in|(R,T)|\} \\
        &= id_{(R,T)}
    \end{align*}

    $(\_,\_)$ preserves composition:
    \begin{adjustwidth}{1.5em}{}
        Define 4 linear maps
        $f : R\multimap T$,
        $h : T\multimap U$,
        $g : V\multimap W$,
    and $k : W\multimap X$.
    Then we have $(f,g):(R,V)\multimap(T,W),(h,k):(T,W)\multimap(U,X)$, and:
    \end{adjustwidth}

    \begin{align*}
        (h,k)\comp(f,g) &= \{
            \lp(r,v)(u,x)\rp:\exists(t,w)\in|(T,W)| \text{ such that}\\
            &\quad\lp(r,v),(t,w)\rp\in(f,g),\lp(t,w),(u,x)\rp\in(h,k)
        \} \\
        &= \{
            \lp(r,v)(u,x)\rp:\exists t\in|T|,w\in|W| \text{ such that} \\
            &\quad\lp r,t\rp\in f,\lp v,w\rp\in g,\lp t,u\rp\in h,\lp w,x\rp\in k
        \} \\
        &= \{
            \lp(r,v),(u,x)\rp:\lp r,u\rp\in h\comp f,\lp v,x\rp\in k\comp g
        \} \\
        &= (h\comp f,k\comp g)
    \end{align*}

\end{proof}

\subsubsection{Seq}
\begin{definition}
    Let $\la\_;\_\ra:\cohs\times\cohs\to\cohs$ be defined as follows:
    \begin{itemize}
        \item
        For $R,T\in Ob(\cohs)$, $\la R;T\ra\coloneqq(|R|\times|T|,\coh[\la R;T\ra])$ such that:
        $$(r,t)\coh[\la R;T\ra](r',t') \iff r\scoh[R]r'\text{ or }(r=r'\text{ and }t\coh[T]t')$$

        \item
        For $f:R\multimap T$ and $g:U\multimap V$, 
        $\la f;g\ra:\la R;U\ra\multimap\la T;V\ra$ is defined as follows:
        $$\la f;g\ra=\{\lp(r,u),(t,v)\rp:\lp r,t\rp\in f,\lp u,v\rp\in g\}$$
    \end{itemize}
\end{definition}

\begin{lemma}
    $\la\_;\_\ra$ is a functor.
\end{lemma}

\begin{proof}

    $\la\_;\_\ra$ preserves coherence:
    \begin{adjustwidth}{1.5em}{}
        Define $f : R\multimap T$, $g : U\multimap V$.

        First assume that $(r,u)\scoh[\la R;U\ra](r',u')$, and consider pairs $\lp(r,u),(t,v)\rp$, $\lp(r',u'),(t',v')\rp\in \la f;g\ra$. 
        We have that either $r\scoh[R]r'$, or that $r=r'$ and $u\scoh[U]u'$.
        As $f$ and $g$ are linear maps, the former implies that $t\scoh t'$, while the latter implies that $t\coh t'$ and $v\scoh v'$.
        In either case we get that $(t,v)\coh[\la T;V\ra](t',v')$, and as either $t\neq t'$ or $v\neq v'$ we find that the coherence is strict as required.

        Now consider pairs $\lp(r,u),(t,v)\rp,\lp(r,u),(t',v')\rp\in\la f;g\ra$.
        Linearity of $f$ implies that $t\coh[T]t'$.
        We have that either $t\neq t'$, in which case $t\scoh[T]t'$, or that $t=t'$.
        Combining the second case with the linearity of $g$ gives that $t=t'$ and $v\coh[V]v'$, so either case gives us $(t,v)\coh[(T,V)](t',v')$ as required.
    \end{adjustwidth}

    $\la\_;\_\ra$ preserves identity and composition;
    the argument is the same as that from the proof of Lemma \ref{lem:CoparIsFunctor}, with any coherence space $(R,T)$ replaced by $\la R;T\ra$.\\
\end{proof}

\subsubsection{Dual}
\begin{definition}
    Let $\overline{\{\quad\}}:\cohs^{op}\to\cohs$ be defined as follows:
    \begin{itemize}
        \item
        For $R\in Ob(\cohs)$, $\overline{R}=(|R|,\incoh[R])$.

        \item
        For $f:R\multimap T$, $\overline{f}:\overline{T}\multimap\overline{R}$ is defined as follows:
        $$\overline{f}=\{\lp t,r\rp:\lp r,t\rp\in f\}$$
    \end{itemize}
\end{definition}

\begin{lemma}
    $\overline{\{\quad\}}$ is a functor
\end{lemma}

\begin{proof}

    $\overline{\{\quad\}}$ preserves coherence:
    \begin{adjustwidth}{1.5em}{}
        Define $f:R\multimap T$

        Take $t,t'\in|T|$ such that $t\scoh[\overline{T}]t'$, that is, $t\incoh[T]t'$.
        Consider pairs $\lp t,r\rp,\lp t',r'\rp\in\overline{f}$, so we have pairs $\lp r,t\rp,\lp r',t'\rp\in f$.
        As $t\incoh[T]t'$, the contrapositive to the linearity of $f$ gives that $r\incoh[R]r'$, and thus $r\scoh[\overline{R}]r'$ as required.

        If we instead consider pairs $\lp t,r\rp,\lp t,r'\rp\in\overline{f}$, we have pairs $\lp r,t\rp,\lp r',t\rp\in f$.
        Then $t=t'\implies t\incoh[T]t'$, and again the contrapositive of linearity of $f$ gives $r\incoh[R]r'$, thus $r\coh[\overline{R}]r'$ as required.

    \end{adjustwidth}

    $\overline{\{\quad\}}$ preserves identity trivially, as the underlying set of $\overline{R}$ is the same as that of $R$:

    $\overline{\{\quad\}}$ preserves composition:
    \begin{adjustwidth}{1.5em}{}
        Define 2 linear maps $f:R\multimap T$, $g:T\multimap U$. Then:
    \end{adjustwidth}
    \begin{align*}
        \overline{f}\comp\overline{g} &= \{\lp u,r\rp:\exists t \text{ such that } \lp u,t\rp\in \overline{g},\lp t,r\rp\in \overline{f}\} \\
        &= \{\lp u,r\rp:\exists t \text{ such that } \lp r,t\rp\in f,\lp t,u\rp\in g\} \\
        &= \{\lp u,r\rp:\lp r,u\rp\in g\comp f\} \\
        &= \overline{g\comp f}
    \end{align*}

\end{proof}

\subsubsection{Dagger}
\begin{definition}
    Let $\dag\_:\cohs\to\cohs$ be defined as follows:

    \begin{itemize}
        \item
        For $R\in Ob(\cohs)$, $\dag R=(|R|^*,\coh[\dag R])$, such that:
        $$r_1...r_m \coh r'_1...r'_n \iff \text{one of:}$$

        \begin{itemize}
            \item
            $\exists 1\leq l \leq \min(m,n) \text{ s.t. } r_i=r'_i \enspace\forall i<l$, and $r_l \scoh[R] r'_l$

            \item
            $r_i = r'_i \enspace\forall i\le\min(m,n)$
        \end{itemize}

        (Informally, 2 words over $R$ are coherent in $\dag R$ if one is a prefix of the other, or if the first place they differ they do so strictly coherently)

        \item
        For $f:R\multimap T$, $\dag f:\dag R\multimap\dag T$ is defined as follows:
        $$\dag f=\{\lp r_1...r_n,t_1...t_n\rp:\lp r_i,t_i\rp\in f\enspace\forall 1\le i\le n\}$$
    \end{itemize}
\end{definition}

\begin{lemma}
    $\dag\_$ is a functor
\end{lemma}

\begin{proof}

    $\dag\_$ preserves coherence:
    \begin{adjustwidth}{1.5em}{}
        Define $f:R\multimap T$.

        First assume that $r_1...r_n\scoh[\dag R]r'_1...r'_n$, and consider pairs $\lp r_1...r_n,t_1...t_n\rp$, $\lp r'_1...r'_n,t'_1...t'_n\rp\in\dag f$.
        $\exists 1\le j\le n$ where $j$ is the smallest index such that $r_j\scoh[R]r'_j$.
        Linearity of $f$ then gives that $t_i\coh[T]t'_i\enspace\forall 1\le i\le j$, so in the first position that they differ they must do so coherently 
        (even if all of $t_i=t'_i$, linearity of $f$ ensures that $t_j\scoh[T]t'_j$).
        This gives $t_1...t_n\scoh[\dag T]t'_1...t'_n$ as required.

        Now consider pairs $\lp r_1...r_n,t_1...t_n\rp$, $\lp r_1...r_n,t'_1...t'_n\rp\in\dag f$.
        Linearity of $f$ gives that $t_i\coh[T]t'_i\enspace\forall1\le i\le n$.
        If $t_1...t_n=t'_1...t'_n$ then the proof is trivial, so assume they are not equal.
        $\exists 1\le j\le n$ where $j$ is the smallest index such that $t_j\neq t'_j$.
        However, as $t_j\coh[T]t'_j$, we must have that $t_j\scoh[T]t'_j$, giving $t_1...t_n\coh[\dag T]t'_1...t'_n$ as required.
    \end{adjustwidth}

    $\dag\_$ preserves identity:
    \begin{align*}
        \dag id_{R} &= \{\lp r_1...r_n,r_1...r_n\rp:\lp r_i,r_i\rp\in id_R\enspace\forall 1\le i\le n\} \\
        &= \{\lp r_1...r_n,r_1...r_n\rp:r_i\in |R|\enspace\forall 1\le i\le n\} \\
        &= id_{\dag R}
    \end{align*}

    $\dag\_$ preserves composition:
    \begin{adjustwidth}{1.5em}{}
        Define 2 linear maps $f:R\multimap T$, $g:T\multimap U$. Then:
    \end{adjustwidth}
    \begin{align*}
        \dag g\comp \dag f &= \{\lp r_1...r_n,u_1u_2...u_n\rp:\exists t_1...t_n\in|T|^* \text{ such that } \\
        &\quad\lp r_1...r_n,t_1...t_n\rp\in\dag f, \lp t_1...t_n,u_1u_2...u_n\rp\in\dag g\} \\
        &= \{\lp r_1...r_n,u_1u_2...u_n\rp:\exists t_i\in|T|\text{ such that } \\
        &\quad\lp r_i,t_i\rp\in f,\lp t_i,u_i\rp\in g\enspace\forall 1\le i\le n\} \\
        &= \{\lp r_1...r_n,u_1u_2...u_n\rp:\lp r_i,u_i\rp\in g\comp f \enspace\forall 1\le i\le n\} \\
        &= \dag(g\comp f)
    \end{align*}

\end{proof}

\subsubsection{Par and Hash}
The remaining connectives, Par and Hash, can be constructed compositionally, as they are the duals of Copar and Dagger respectively.
That is, we can define:
$$[\_,\_]\coloneqq\overline{(\overline{\{\quad\}},\overline{\{\quad\}})}:\cohs\times\cohs\to\cohs$$
$$\hash \_\coloneqq\overline{\dag\overline{\{\quad\}}}:\cohs\to\cohs$$

Deriving the actions of these functors is left as an exercise to the reader; the results are as follows:

\begin{itemize}
    \item
    For $R,T\in Ob(\cohs)$, $[R,T] \coloneqq (R\times T,\coh[{[R,T]}])$ such that:
    $$(r,t)\coh[{[R,T]}](r',t')\iff r\scoh[R]r'\text{ or }t\scoh[T]t'\text{ or }(r,t)=(r',t')$$

    \item
    For $f:R\multimap T$ and $g:U\multimap V$, 
    $[f,g]:[R,U]\multimap[T,V]$ is defined as follows:
    $$[f,g]=\{\lp(r,u),(t,v)\rp:\lp r,t\rp\in f,\lp u,v\rp\in g\}$$

    \item
        For $R\in Ob(\cohs)$, $\hash R=(|R|^*,\coh[\hash R])$, such that:
        $$r_1...r_m \coh r'_1...r'_n \iff \text{one of:}$$

        \begin{itemize}
            \item
            $\exists 1\leq l \leq \min(m,n) \text{ s.t. } r_i=r'_i \enspace\forall i<l$, and $r_l \scoh[R] r'_l$

            \item
            $r_1...r_m=r'_1...r'_n$
        \end{itemize}

        (Informally, 2 words over $R$ are coherent in $\hash R$ if they are equal, or if the first place they differ they do so strictly coherently)

        \item
        For $f:R\multimap T$, $\hash f:\hash R\multimap\hash T$ is defined as follows:
        $$\hash f=\{\lp r_1...r_n,t_1...t_n\rp:\lp r_i,t_i\rp\in f\enspace\forall 1\le i\le n\}$$
\end{itemize}

We do not have to prove that these are functors, as composition of functors always results in functors.

With these final 2 functors, we now have a purely categorical model of any structure that could arise from the grammar of $\sSys$, which preserves all necessary properties no matter the choice of coherence space for atoms.

\subsection{Rewrite Rules are Linear Maps} 
For each rewrite rule of $\sSys$, we define a family of linear maps between coherence spaces to be its model.
The map representing some rewrite rule $\vlinf{\rho}{}{T}{R}$ will be of the form $\rho_R:R\multimap T$;
we will use the notation $\rho_{\_}$ to denote the family of linear maps representing the polymorphic map $\rho$, applicable to arbitrary structures.

We will consider the simplest form of each rule, that is, applying each in an empty context.
Extending this to rewrites in arbitrary contexts is automatic, as we can represent the context as a functor. 

Suppose we have a rule $\rho$ as above, and would like to apply it inside of a context
$$S=\dag\la\{\quad\};\overline{(U,V)}\ra$$
to perform the following rewrite:
$$\vlinf{\rho}{}{\dag\la T;\overline{(U,V)}\ra}{\dag\la R;\overline{(U,V)}\ra}$$

We can compose the functors $\dag\_,\la\_;\_\ra,\overline{\{\quad\}},$ and $(\_,\_)$ to create the functor
$$\dag\la\_;\overline{(\_,\_)}\ra:\cohs\times\cohs^{op}\times\cohs^{op}\to\cohs$$
which, when $U$ and $V$ are put into the second and third slots, gives us a representation of a structure with a single hole:
$$\dag\la\_;\overline{(U,V)}\ra:\cohs\to\cohs$$

Finally, we can apply this to $\rho_R$ to get the linear map representing the application of $\rho$ to $R$ in the context $S$.

We will later prove that the same result is obtained whether we first apply the context functor to the linear map, and then apply this new map to the structure representation, or instead apply the rewrite rule to the structure representation and then the context functor to this result.
Crucially, we must first show that each of these maps preserve coherence (and thus cliques), which will allow chains of rewrites to model derivations (and thus proofs).

\subsubsection{$\aiD$}
\begin{definition}
    To model the rewrite
    \[
        \vlderivation{
            \vlin{\aiD}{}{[a,\overline{a}]}
            {\vlhy{\unit}}
            }
        \]

    we define $\aiD_a:\unit\multimap[a,\overline{a}]$ as follows:
    $$\aiD_a=\{\lp *,(\alpha,\alpha)\rp:\alpha\in|a|\}$$
\end{definition}

\begin{lemma}\label{lem:aiPreserves}
    $\aiD_a$ is a linear map
\end{lemma}

\begin{proof}
    As $*\incoh[\unit]*$, preservation of strict coherence is vacuously true.
    Now consider pairs $\lp*,(\alpha,\alpha)\rp,\lp*,(\beta,\beta)\rp\in \aiD_{\unit}$.
    As $*=*$ and thus $*\coh*$, we must show that $(\alpha,\alpha)\coh[{[a,\overline{a}]}](\beta,\beta)$.
    If $\alpha=\beta$ the coherence is trivial, so suppose that $\alpha\neq\beta$.
    We either have that $\alpha\scoh[a]\beta$, in which case we get $(\alpha,\alpha)\coh[{[a,\overline{a}]}](\beta,\beta)$, or that $\alpha\incoh[a]\beta$.
    In the latter case, we get that $\alpha\scoh[\overline{a}]\beta$, and so $(\alpha,\alpha)\coh[{[a,\overline{a}]}](\beta,\beta)$.
\end{proof}
\subsubsection{$\wD$}
\begin{definition}
    To model the rewrite
    \[
        \vlderivation{
            \vlin{\wD}{}{\hash R}
            {\vlhy{\unit}}
            }
        \]

    we define $\wD_R:\unit\multimap\hash R$ as follows:
    $$\wD_R=\{\lp *,\epsilon\rp\}$$
    where $\epsilon$ is the empty sequence in $R$
\end{definition}

\begin{lemma}
    $\wD_R$ is a linear map
\end{lemma}

\begin{proof}
    Trivial, as any two empty sequences in $R$ are coherent by equality.
\end{proof}

\subsubsection{$\dD$}
\begin{definition}
    To model the rewrite
    \[
        \vlderivation{
            \vlin{\dD}{}{\dag\unit}
            {\vlhy{\unit}}
            }
        \]

    we define $\dD_{\unit}:\unit\multimap\dag\unit$ as follows:
    $$\dD_{\unit}=\{\lp *,*^n\rp:n\in\mathbb{N}\}$$
\end{definition}

\begin{lemma}
    $\dD_{\unit}$ is a linear map
\end{lemma}

\begin{proof}
    Trivial, as $*^m$ prefixes $*^n$ for $m\le n$, while $*^n$ prefixes $*^m$ for $n<m$.
\end{proof}

\subsubsection{$\sw$}
\begin{definition}
    To model the rewrite
    \[
        \vlderivation{
            \vlin{\sw}{}{[(R,U),T]}
            {\vlhy{([R,T],U)}}
            }
        \]

    we define $\sw_{R,T,U}:([R,T],U)\multimap[(R,U),T]$ as follows:
    $$\sw_{R,T,U}=\{\lp(r,t,u),(r,u,t)\rp:r\in|R|,t\in|T|,u\in|U|\}$$
\end{definition}

\begin{lemma}
    $\sw_{R,T,U}$ is a linear map
\end{lemma}

\begin{proof}
    Consider $(r,t,u),(r',t',u')\in|([R,T],U)|$.

    If the two are equal, it is trivial to show that $\sw_{R,T,U}$ preserves this equality.
    Assume instead that $(r,t,u)\scoh(r',t',u')$.
    To get the required coherence $(r,u,t)\scoh[{[(R,U),T]}](r',u',t')$, it suffices to show that either $(r,u)\scoh[(R,U)](r',u')$ or $t\scoh t'$.
    We have 2 possible cases:

    Case 1: $(r,t)\scoh[{[R,T]}](r',t')$ and $u\coh u'$
    \begin{adjustwidth}{1.5em}{}
        $(r,t)\scoh(r',t')\implies r\scoh r'$ or $t\scoh t'$.
        The latter alone suffices, and the former combined with $u\coh u'$ gives $(r,u)\scoh[(R,U)](r',u')$ as required.
    \end{adjustwidth}

    Case 2: $(r,t)\coh[{[R,T]}](r',t')$ and $u\scoh u'$
    \begin{adjustwidth}{1.5em}{}
        The same 2 cases as above can arise here, or alternatively we may have that $(r,t)=(r',t')$.
        In this case, we have that $r\coh r'$, which combined with $u\scoh u'$ gives $(r,u)\scoh[(R,U)](r',u')$ as required.
    \end{adjustwidth}
\end{proof}

\subsubsection{$\qD$}
\begin{definition}
    To model the rewrite
    \[
        \vlderivation{
            \vlin{\qD}{}{[\la R;U\ra,\la T;V\ra]}
            {\vlhy{\la[R,T];[U,V]\ra}}
            }  
        \]

    we define $\qD_{R,T,U,V}:\la[R,T];[U,V]\ra\multimap[\la R;U\ra,\la T;V\ra]$ as follows:
    $$\qD_{R,T,U,V}=\{\lp(r,t,u,v),(r,u,t,v)\rp:r\in|R|,t\in|T|,u\in|U|,v\in|V|\}$$
\end{definition}

\begin{lemma}
    $\qD_{R,T,U,V}$ is a linear map
\end{lemma}
\begin{proof}
    Consider $(r,t,u,v),(r',t',u',v')\in|\la[R,T];[U,V]\ra|$.

    If the two are equal, it is trivial to show that $\qD_{R,T,U,V}$ preserves this equality.
    Assume instead that $(r,t,u,v)\scoh(r',t',u',v')$.
    To get the required coherence $(r,u,t,v)\scoh[{[\la R;U\ra,\la T;V\ra]}](r',u',t',v')$,
    it suffices to show that either $(r,u)\scoh[\la R;U\ra](r',u')$ or $(t,v)\scoh[\la T;V\ra](t',v')$.
    We have 2 possible cases:

    Case 1: $(r,t)\scoh[{[R,T]}](r',t')$
    \begin{adjustwidth}{1.5em}{}
        We have that either $r\scoh r'$, implying $(r,u)\scoh(r',u')$, or $t\scoh t'$, in which case $(t,v)\scoh(t',v')$.
        In either case the sufficient condition is met.
    \end{adjustwidth}

    Case 2: $(r,t)=(r',t')$ and $(u,v)\scoh[{[U,V]}](u',v')$
    \begin{adjustwidth}{1.5em}{}
        We have that either $u\scoh u'$ or $v\scoh v'$.
        As $r=r'$, the former implies $(r,u)\scoh(r',u')$, and similarly the latter implies $(t,v)\scoh(t',v')$.
        In either case the sufficient condition is met.
    \end{adjustwidth}
\end{proof}

\subsubsection{$\pD$}
\begin{definition}
    To model the rewrite
    \[
        \vlderivation{
            \vlin{\pD}{}{[\dag R,\hash T]}
            {\vlhy{\dag[R,T]}}
            }  
        \]

    we define $\pD_{R,T}:\dag[R,T]\multimap[\dag R,\hash T]$ as follows:
    $$\pD_{R,T}=\{\lp (r_1,t_1)...(r_n,t_n),(r_1...r_n,t_1...t_n)\rp:r_i\in|R|,t_j\in|T|\}$$
\end{definition}

\begin{lemma}
    $\pD_{R,T}$ is a linear map
\end{lemma}

\begin{proof}
    Consider $(r_1,t_1)...(r_m,t_m),(r'_1,t'_1)...(r'_n,t'_n)\in|\dag[R,T]|$

    If the two are equal, it is trivial to show that $\pD_{R,T}$ preserves this equality.
    Assume instead that $(r_1,t_1)...(r_m,t_m)\scoh[\dag{[R,T]}](r'_1,t'_1)...(r'_n,t'_n)$,
    considering pairs $\lp (r_1,t_1)...(r_m,t_m),(r_1...r_m,t_1...t_m)\rp$, $\lp (r'_1,t'_1)...(r'_n,t'_n),(r'_1...r'_n,t'_1...t'_n)\rp$ .
    We have 2 possible cases:
    
    Case 1: $\exists 1\leq l \leq \min(m,n) \text{ s.t. } (r_i,t_i)=(r'_i,t_i) \enspace\forall i<l$, and $(r_l,t_l)\scoh[{[R,T]}](r'_l,t'_l)$
    \begin{adjustwidth}{1.5em}{}
        Assume WLOG that $r_l\scoh[R]r'_l$.
        We then have that $r_i=r'_i\enspace\forall 1\le i\le l$, and $r_l\scoh[R]r'_l$.
        This implies that $r_1...r_m\scoh[\dag R]r'_1...r'_n$, which then gives $(r_1...r_m,t_1...t_m)\scoh[{[\dag R,\hash T]}](r'_1...r'_n,t'_1...t'_n)$ as required.
    \end{adjustwidth}

    Case 2: $(r_i,t_i)=(r'_i,t_i')\enspace\forall 1\le i\le \text{min}(m,n)$
    \begin{adjustwidth}{1.5em}{}
        We get that $r_i=r'_i\enspace\forall 1\le i\le \text{min}(m,n)$.
        As $(r_1,t_1)...(r_m,t_m)\scoh[\dag{[R,T]}](r'_1,t'_1)...(r'_n,t'_n)$, it follows that $m\neq n$.
        This implies that $r_1...r_m\scoh[\dag R]r'_1...r'_n$, and so $(r_1...r_m,t_1...t_m)\scoh[{[\dag R,\hash T]}](r'_1...r'_n,t'_1...t'_n)$ as required.
    \end{adjustwidth}
\end{proof}

\subsubsection{$\bD$}
\begin{definition}
    To model the rewrite
    \[
        \vlderivation{
            \vlin{\bD}{}{\hash R}
            {\vlhy{\la R;\hash R\ra}}
            }  
        \]

    we define $\bD_{R}:\la R;\hash R\ra\multimap\hash R$ as follows:
    $$\bD_{R}=\{\lp(r_0,r_1...r_n),r_0r_1...r_n\rp:r_i\in|R|\}$$
\end{definition}

\begin{lemma}
    $\bD_{R}$ is a linear map
\end{lemma}

\begin{proof}
    Consider $(r_0,r_1...r_m),(r'_0,r'_1...r'_n)\in|\la R;\hash R\ra|$.

    If the two are equal, it is trivial to show that $\bD_{R}$ preserves this equality.
    Assume instead that $(r_0,r_1...r_m)\scoh[\la R;\hash R\ra](r'_0,r'_1...r'_n)$.
    We have that either $r_0\scoh[R]r'_0$, or that $r_0=r'_0$ and $r_1...r_m\scoh[\hash R]r'_1...r'_n$.
    In either case, $r_0r_1...r_m\neq r'_0r'_1...r'_n$, and the first place they differ they do so strictly coherently,
    giving $r_0r_1...r_m\scoh[\hash R]r'_0r'_1...r'_n$ as required.
\end{proof}

\subsubsection{Up Rules}
We can once again leverage the idea of duality to construct models the remaining rewrite rules.
By applying the $\overline{\{\quad\}}$ functor to the model for any "down" rule, we get the model for the corresponding "up" rule.
Verifying that the resulting linear maps do behave as intended is left as an exercise to the reader.

\subsection{Proofs are Cliques}
PUT SOME STUFF HERE, TALK MAINLY ABOUT HOW WE COULD MAKE THIS BETTER WITH TOTALITY SPACES.
\newpage
\section{Dinaturality of Derivations}

REDO THIS WORDING.
In order to correctly model derivations, we require a certain freedom regarding the order that we can apply rewrite rules and context functors.
As mentioned previously, applying a context to a both sides of a rewrite should yield the same result as applying the context to the rewritten structure.
This required property of rewrite rules, when considered as linear maps of coherence spaces, is naturality.

We first give formal definitions of the category theoretic concepts at play, namely natural and dinatural transformations. 
Then, we show a few key examples of rewrites behaving in the intended way, and classify each rewrite rule's map as one of these types.
Finally, we use a key result proved by McCusker and Santamaria to show that we can compose arbitrarily many rewrites into a derivation and still enjoy the same properties.

\subsection{Natural and Dinatural Transformations}
\begin{definition}
Given functors $F,G:\mathbb{C}\to\mathbb{D}$, a \textit{natural transformation} $\phi:F\to G$ is a family of morphisms $\phi_A:FA\to GA$, such that for any $f\in \text{Hom}_{\mathbb{C}}(A,B)$ the following diagram commutes:
\[
\begin{tikzcd}
    FA \arrow[r,"Ff"]\arrow[d,"\phi_A"]& FB\arrow[d,"\phi_B"] \\
    GA \arrow[r,"Gf"] & GB
\end{tikzcd}
\]
\end{definition}

It is a standard result that the composition of two natural transformations is itself a natural transformation \cite{leinster2016basic}.

\begin{definition}
Given functors $F,G:\mathbb{C}\times\mathbb{C}^{op}\to\mathbb{D}$, a \textit{dinatural transformation} $\psi:F\to G$ is a family of morphisms
$\psi_A:F(A,A)\to G(A,A)$, such that for any $f\in\text{Hom}_{\mathbb{C}}(A,B)$ the following diagram commutes:
\[
\begin{tikzcd}
    & F(A,A) \arrow[r,"\psi_A"] & G(A,A) \arrow[rd,"{G(f,1)}"] \\
    F(A,B) \arrow[ru,"{F(1,f)}"] \arrow[rd,"{F(f,1)}"] &&& G(B,A) \\
    & F(B,B) \arrow[r,"\psi_B"] & G(B,B) \arrow[ru,"{G(1,f)}"]
\end{tikzcd}
\]
where $1$ is the identity morphism.
\end{definition}

Unlike natural transformations, dinatural transformations do not compose in general \cite{mccusker2018compositionality}.
We will spend the rest of this section discussing the specific situations in which the transformations representing our rewrites can compose.
The following proposition allows us to speak more generally about the two classes of transformations, and state results only in terms of dinatural transformations.

\begin{proposition}
Every natural transformation is a dinatural transformation
\end{proposition}

\begin{proof}
The proof is left as an exercise in applying the definitions, showing that if we define $F'(A,B) \coloneq F(A)$ and $G'(A,B) \coloneq G(B)$, the dinaturality diagram collapses into the naturality one.
I THINK??????
\end{proof}

\begin{remark}
We will thus occasionally refer to \textit{strictly dinatural transformations}, meaning those which are dinatural but not natural, in cases where the distinction is necessary.
\end{remark}

\subsection{Classifying Rewrite Rules}

We briefly introduce some new terminology with which to classify rewrite rules of $\sSys$.
\begin{definition}
We call a rewrite rule $\vlinf{\rho}{}{T}{R}$ of $\sSys$ a \textit{(di)natural rewrite} if its model as a family of linear maps $\rho_{\_}$ is a (di)natural transformation.
\end{definition}

We will classify all rewrite rules of $\sSys$, but only give proofs for a select few, as they follow the same general structure.
The following proposition also limits the amount of rules we need to classify.

\begin{proposition}
An up-down pair of rewrite rules ${\mathsf{\rho}}{\uparrow},{\mathsf{\rho}}{\downarrow}$ must both have the same classification.
\end{proposition}

\begin{proof}
We use a commuting diagram to show the (di)naturality of any rule $\rho$.
As an up-down pair are, by definition, dual to each-other, we can simply take duals and reverse the arrows in the proof of ${\mathsf{\rho}}{\uparrow}$'s classification to get an equivalent one for ${\mathsf{\rho}}{\downarrow}$.
\end{proof}

We find that all rewrite rules in $\sSys$ are dinatural, and that all but $\aiD$ and $\aiU$ are in fact natural.
The intuition behind this is that $\aiD$  and $\aiU$ are the only rewrites which deal explicitly with negative structures, which correspond to the objects of $\cohs^{op}$ present in strictly dinaural transformations.
All other rewrites either shuffle substructures and exchange structure brackets, or duplicate/combine instances of the same substructure; in either case, the corresponding transformation is natural.
We give proofs for 2 cases, noting that the others follow a similar format and so are left as an exercise to the reader.

\begin{lemma}
$\sw$ is a natural rewrite.
\end{lemma}

\begin{proof}
Following the definitions, we see that the required $F$ and $G$ are as follows:

$$([\_,\_],\_),[(\_,\_),\_]:\cohs\times\cohs\times\cohs\to\cohs$$
We thus need to show that for any $g:R\multimap R'$, $h:T\multimap T'$, and $k:U\multimap U'$, the following diagram commutes:

\[
\begin{tikzcd}[column sep = large]
    ([R,T],U) \arrow[r,"{([g,h],k)}"]\arrow[d,"\sw_{R,T,U}"]& ([R',T'],U') \arrow[d,"\sw_{R',T',U'}"] \\
    {[(R,U),T]} \arrow[r,"{[(g,k),h]}"] & {[(R',U'),T']}
\end{tikzcd}
\]

Indeed,

\begin{align*}
\sw_{R',T',U'}\comp ([g,h],k) &= \{\lp(r,t,u),(r',u',t')\rp: \\
&\quad\lp(r,t,u),(r',t',u')\rp\in([g,h],k),\lp(r',t',u'),(r',u',t')\rp\in \sw_{R',T',U'}\} \\
&= \{\lp(r,t,u),(r',u',t')\rp:\lp r,r'\rp\in g, \lp t,t'\rp\in h, \lp u,u'\rp\in k\} \\
&= \{\lp(r,t,u),(r',u',t')\rp: \\
&\quad\lp(r,t,u),(r,u,t)\rp\in \sw_{R,T,U},\lp(r,u,t),(r',u',t')\rp\in[(g,k),h]\} \\
&= [(g,k),h]\comp \sw_{R,T,U}
\end{align*}
\end{proof}

\begin{lemma}
$\bU$ is a natural rewrite.
\end{lemma}

\begin{proof}
Here, the definitions give us $F = \dag\_, G = \la\_;\dag\_\ra$, and we are required to show that for all $g:R\multimap R'$ the following diagram must commute:

\[
\begin{tikzcd}
    \dag R \arrow[r,"\dag g"]\arrow[d,"\bU_{R}"]& \dag R' \arrow[d,"\bU_{R'}"] \\
    \la R; \dag R\ra \arrow[r,"\la g;\dag g\ra"] & \la R';\dag R'\ra
\end{tikzcd}
\]

Indeed,

\begin{align*}
\bU_{R'}\comp\dag g &= \{\lp r_0...r_n,(r'_0,r'_1...r'_n)\rp: \\
&\quad\lp r_0...r_n,r'_0...r'_n\rp\in\dag g,\lp r'_0...r'_n,(r'_0,r'_1...r'_n)\rp\in\bU_{R'}\} \\
&= \{\lp r_0...r_n,(r'_0,r'_1...r'_n)\rp:\lp r_i,r'_i\rp\in g\} \\
&= \{\lp r_0...r_n,(r'_0,r'_1...r'_n)\rp: \\
&\quad\lp r_0...r_n,(r_0,r_1...r_n)\rp\in\bU_{R},\lp(r_0,r_1...r_n),(r'_0,r'_1...r'_n)\rp\in\la g;\dag g\ra\} \\
&= \la g;\dag g\ra\comp\bU_{R}
\end{align*}
\end{proof}

We then turn our attention to the strictly dinatural rewrites.
A proof is given for the dinaturality of $\aiD$.
The corresponding proof for $\aiU$ can be easily derived, as stated previously, by taking duals and reversing arrows.

\begin{lemma}
$\aiD$ is a dinatural rewrite.
\end{lemma}

\begin{proof}
Following the definitions, we find that the required $F$ is the trivial functor $\unit:\cohs\times\cohs^{op}\to\cohs$.
This sends any pair of coherence spaces to the trivial coherence space $*$, and all linear maps to the identity.
Then $G$ is
$$[\_,\overline{\{\enspace\}}]:\cohs\times\cohs^{op}\to\cohs$$
For any $g:a\multimap b$, the required commutative diagram is

\[
\begin{tikzcd}
    & * \arrow[r,"\aiD_{a}"] & {[a,\overline{a}]} \arrow[rd,"{[g,id_{\overline{a}}]}"] \\
    * \arrow[ru,"id"] \arrow[rd,"id"] &&& {[b,\overline{a}]} \\
    & * \arrow[r,"\aiD_{b}"] & {[b,\overline{b}]} \arrow[ru,"{[id_a,\overline{g}]}"]
\end{tikzcd}
\]

which can be simplified to the following:

\[
\begin{tikzcd}
    * \arrow[r, "\aiD_{a}"]\arrow[d,"\aiD_{b}"] & {[a,\overline{a}]} \arrow[d,"{[g,id_{\overline{a}}]}"] \\
    {[b,\overline{b}]} \arrow[r,"{[id_b,\overline{g}]}"] & {[b,\overline{a}]}
\end{tikzcd}
\]

Indeed,

\begin{align*}
    [g,id_{\overline{a}}]\comp\aiD_{a} &= \{\lp*,(\beta,\alpha)\rp:\lp*,(\alpha,\alpha)\rp\in \aiD_{a},\lp(\alpha,\alpha),(\beta,\alpha)\rp\in[g,id_{\overline{a}}]\} \\
    &= \{\lp*,(\beta,\alpha)\rp:\lp\alpha,\beta\rp\in g\} \\
    &= \{\lp*,(\beta,\alpha)\rp:\lp*,(\beta,\beta)\rp\in \aiD_{b},\lp(\beta,\beta),(\beta,\alpha)\rp\in[id_{b},\overline{g}]\}\\
    &= [id_b,\overline{g}]\comp\aiD_{b}
\end{align*}
\end{proof}

Now that all rewrite rules have been classified, we investigate how their dinaturality is preserved when they are composed to form derivations.

\subsection{Preserving Dinaturality through Composition}

\subsubsection{Graphical Representation of Derivations}
As we know that all derivations in $\sSys$ can be modelled by composing a number of dinatural transformations, we are able to represent them as simple graphs.
Each argument of a functor is a box, and applications of the transformations are lines between them.
In our case, white boxes represent objects of $\cohs$ and grey ones represent those of $\cohs^{op}$.
These graphs are an extension of Kelly-Mac Lane graphs \cite{mac2013categories}, and are introduced formally by McCusker and Santamaria \cite{mccusker2018compositionality}.

\begin{definition}
We call a graph of this type \textit{well-formed} if it is the representative graph of a well formed derivation in $\sSys$.
\end{definition}

The example below shows the correspondence between a derivation and its representation as a graph:

\begin{figure}[ht]
    \centering
    \begin{minipage}[h]{0.45\textwidth}
        \[
        \vlderivation{
            \vlin{\bU}{}{[(b,\la a;\dag a\ra),\overline{b}]}{
            \vlin{\sw}{}{[(b,\dag a),\overline{b}]}{
            \vlin{\aiD}{}{([b,\overline{b}],\dag a)}{
            \vlhy{\dag a}
        }}}}
        \]
    \end{minipage}
    \hfill
    \begin{minipage}[h]{0.5\textwidth}
        \centering
        \begin{tikzpicture}[
            every node/.style={draw, minimum size=0.5cm},
            invisible/.style={draw=none, fill=none, inner sep=0pt, minimum size=0pt},
            graybox/.style={draw, fill=gray!50}, thick,
        ]
        \node (n0) at (2,0) {};

        \node (n1) at (0,-1) {};
        \node (n2) at (1,-1) [graybox] {};
        \node (n3) at (2,-1) {};
        
        \node (n4) at (0,-2) {};
        \node (n5) at (1,-2) {};
        \node (n6) at (2,-2) [graybox] {};

        \node[invisible] (split) at (1,-2.5) {};
        
        \node (n7) at (-0.5,-3) {};
        \node (n8) at (0.5,-3) {};
        \node (n9) at (1.5,-3) {};
        \node (n10) at (2.5,-3) [graybox] {};
        
        \draw[->] (n0) -- (n3);
        \draw[->] (n1) to[out=90, in=90, looseness=1.7] (n2);

        \draw[->] (n1) -- (n4);
        \draw[->] (n2) -- (n6);
        \draw[->] (n3) -- (n5);
        
        \draw[->] (n4) -- (n7);
        \draw[->] (n5) -- (split);
        \draw[->] (split) -- (n8);
        \draw[->] (split) -- (n9);
        \draw[->] (n6) -- (n10);
        
        \end{tikzpicture}
    \end{minipage}

    \caption{A derivation in $\sSys$ and its graph}
    \label{fig:graph}
\end{figure}

This representation abstracts away many of the details of the transformations themselves.
It also leads to a simple sufficient condition for a composition of dinatural transformations to be dinatural:

\begin{theorem}\label{thm:acyclic-dinatural}
Any composition of dinatural transformations whose graph is acyclic is itself dinatural.
\end{theorem}

\begin{proof}
The proof is given by McCusker and Santamaria \cite{mccusker2018compositionality}.
\end{proof}

Note that at the top and bottom of any cycle is necessarily an arrow between a white and a grey box, pointing in opposite directions. 
Looking specifically at $\sSys$, in which the only two dinatural rewrites are $\aiU$ and $\aiD$, the only possible interactions between a white and a grey box are shown in Figure \ref{fig:cycles}.
We can deduce that a cycle could form if the conclusion of an $\aiD$ rewrite became the premise of an $\aiU$.

\begin{figure}[ht]
    \begin{minipage}[h]{0.3\textwidth}
        \centering
        \begin{tikzpicture}[
            every node/.style={draw, minimum size=0.5cm},
            graybox/.style={draw, fill=gray!50}, thick,
        ]
        \node (n0) at (0,0) {};
        \node (n1) at (1,0) [graybox] {};
        \draw[->] (n0) to[out=90, in=90, looseness=1.7] (n1);
        \draw[opacity=0, line width=0pt, ->] (n1) to[out=270, in=270, looseness=1.7] (n0);
        \end{tikzpicture}
    \end{minipage}
    \hfill
    \begin{minipage}[h]{0.3\textwidth}
        \centering
        \begin{tikzpicture}[
            every node/.style={draw, minimum size=0.5cm},
            graybox/.style={draw, fill=gray!50}, thick,
        ]
        \node (n0) at (0,0) {};
        \node (n1) at (1,0) [graybox] {};
        \draw[opacity=0, line width=0pt, ->] (n0) to[out=90, in=90, looseness=1.7] (n1);
        \draw[->] (n1) to[out=270, in=270, looseness=1.7] (n0);
        \end{tikzpicture}
    \end{minipage}
    \hfill
    \begin{minipage}[h]{0.3\textwidth}
        \centering
        \begin{tikzpicture}[
            every node/.style={draw, minimum size=0.5cm},
            graybox/.style={draw, fill=gray!50}, thick,
        ]
        \node (n0) at (0,0) {};
        \node (n1) at (1,0) [graybox] {};
        \draw[->] (n0) to[out=90, in=90, looseness=1.7] (n1);
        \draw[->] (n1) to[out=270, in=270, looseness=1.7] (n0);
        \end{tikzpicture}
    \end{minipage}

    \caption{Graphs of $\aiD$ and $\aiU$ respectively, and how they could combine to form a simple cycle}
    \label{fig:cycles}
\end{figure}

We immediately obtain the following result about cut-free proofs, that is, proofs that do not contain any instance of $\aiU$:

\begin{theorem}
Any cut-free derivation in $\sSys$ can be modelled by a dinatural transformation.
\end{theorem}

\begin{proof}
The graph of a cut-free derivation is necessarily acyclic, as there are no instances of $\aiU$ which could provide a "smile" arrow to match up with any "frown".
We then apply Theorem \ref{thm:acyclic-dinatural} to get the desired result.
\end{proof}

Bringing our attention back to general derivations, we look back at Figure \ref{fig:cycles}.
This simple cycle can never occur as the corresponding structure brackets do not match up ($\aiD$ produces a copar conclusion, $\aiU$ requires a par premise, so the graph is not well-formed).
Instead, a more complex cycle may form if we allow additional transformations in-between the applications of $\aiU$ and $\aiD$.
Looking back at the graph in Figure \ref{fig:graph}, we could conceivably add an instance of $\aiU$ at the bottom.
This would introduce an additional arrow (dotted), forming a longer cycle (bolded), as shown in Figure \ref{fig:modification}.

\begin{figure}[ht]
\centering
\begin{tikzpicture}[
    every node/.style={draw, minimum size=0.5cm},
    invisible/.style={draw=none, fill=none, inner sep=0pt, minimum size=0pt},
    graybox/.style={draw, fill=gray!50}, thick,
]
\node (n0) at (2,0) {};

\node (n1) at (0,-1) {};
\node (n2) at (1,-1) [graybox] {};
\node (n3) at (2,-1) {};

\node (n4) at (0,-2) {};
\node (n5) at (1,-2) {};
\node (n6) at (2,-2) [graybox] {};

\node[invisible] (split) at (1,-2.5) {};

\node (n7) at (-0.5,-3) {};
\node (n8) at (0.5,-3) {};
\node (n9) at (1.5,-3) {};
\node (n10) at (2.5,-3) [graybox] {};

\draw[->] (n0) -- (n3);
\draw[->, ultra thick] (n1) to[out=90, in=90, looseness=1.7] (n2);

\draw[->, ultra thick] (n1) -- (n4);
\draw[->, ultra thick] (n2) -- (n6);
\draw[->] (n3) -- (n5);

\draw[->, ultra thick] (n4) -- (n7);
\draw[->] (n5) -- (split);
\draw[->] (split) -- (n8);
\draw[->] (split) -- (n9);
\draw[->, ultra thick] (n6) -- (n10);

\draw[->, dotted, ultra thick] (n10) to[out=270, in=270, looseness=0.8] (n7);

\end{tikzpicture}

\caption{A modification of a graph with a cycle formed}
\label{fig:modification}
\end{figure}

We must verify that this new graph, or any constructed in a similar fashion, is not well-formed.

\subsubsection{Derivations are Acyclic}

We will consider the equivalent notion when working purely with the logic.
That is, we must show that for any context $S$ the following derivation cannot be well-formed:

\[
\vlderivation{
\vlin{\aiU}{}{S'\{\unit\}}{
\vlde{\Gamma}{}
{S'(a,\overline{a})}
{\vlin{\aiD}{}{S[a,\overline{a}]}{\vlhy{S\{\unit\}
}}}}}
\]

Firstly, we show that we are not able to freely rewrite the copar substructure $[a,\overline{a}]$ into the par substructure $(a,\overline{a})$.
By analysing the rewrite rules of the system, we can easily verify that this is the case.

\begin{proposition}
For any structures $R$,$T$ of $\sSys$, the following derivation cannot be formed:
$$\vlderivation{\vlde{\Delta}{}{(R,T)}{\vlhy{[R,T]}}}$$

\end{proposition}

\begin{proof}
There are 5 rewrites (besides $\aiU$and $\aiD$) containing either a copar in the premise or a par in the conclusion.
We now analyse each of them individually, deduce which structures can be freely transformed into others, and ultimately show that the copar to par rewrite is impossible in a well-formed structure.
The main technique used is to set certain structures in each rule's definition to the unit, to see how the simplified version of the rule can be applied in more general situations.

\begin{itemize}
    \item 
    $\vlderivation{
        \vlin{\sw}{}{[(R,U),T]}
        {\vlhy{([R,T],U)}}
    }$:

    By setting $R=\unit$ and applying the singleton laws, we are able to rewrite $(T,U)$ to $[T,U]$.
    $\sw$ thus allows us to replace any par structure with a copar.
    Instead setting $T=\unit$ or $U=\unit$ and removing redundant brackets, the rule simply reduces to the identity.

    \item
    $\vlderivation{
        \vlin{\qD}{}{[\la R;U\ra,\la T;V\ra]}
        {\vlhy{\la[R,T];[U,V]\ra}}
        }$:
    
    Here we can set $T=U=\unit$, which once simplified allows a rewrite from $\la R;V\ra$ to $[R,V]$, or indeed any seq structure to a copar.
    Once again, this is the only application of the rule which allows us to directly replace a structure brackets, with all others either shuffling elements between substructures or reducing to the identity.

    \item
    $                \vlderivation{
        \vlin{\qU}{}{\la(R,U);(T,V)\ra}
        {\vlhy{(\la R;T\ra,\la U;V\ra)}}
        }$

    This is the dual of $\qD$; it is unsurprising that by taking the dual of each structure and swapping premise with conclusion, we can rewrite a par structure into a seq.
    This result is easily verified by once again setting $T=U=\unit$.

    \item
    $\vlderivation{
        \vlin{\pU}{}{\hash(R,T)}
        {\vlhy{(\hash R,\dag T)}}
        }$, 
    $\vlderivation{
        \vlin{\pD}{}{[\dag R, \hash T]}
        {\vlhy{\dag[R,T]}}
        }$:

    While these do contain the structures of interest, they only introduce new unary connectives.
    As they do not exchange any structure brackets, they do not contribute to our search.
\end{itemize}

Of the 5 rewrites above, only 3 direct exchanges of structure brackets have been shown to be possible:
$(...)\to[...]$, $\la ...\ra\to[...]$, and $(...)\to\la ...\ra$.
This is better demonstrated visually as a hierarchy of structure brackets, in which we are free to move down the list but unable to climb back up:

\begin{center}
    \begin{tikzpicture}
        \node (A) at (0,2) {\( (...) \)};
        \node (B) at (0,1) {\( \la ... \ra \)};
        \node (C) at (0,0) {\( [...] \)};

        \draw[->, bend left=20] (A.east) to node[right] {$\qU$} (B.east);
        \draw[->, bend left=20] (B.east) to node[right] {$\qD$} (C.east);
        \draw[->, bend right=40] (A.west) to node[left] {$\sw$} (C.west);
    \end{tikzpicture}
\end{center}

This shows that the proposed rewrite is indeed impossible.
\end{proof}

For a full proof that we can freely chain rewrite rules and represent them as dinatural transformations, we must consider how the context $S\{\}$ may interact with the substructure.
We must give particular care to the case that context contains exponentials, and verify that duplication of structures does not lead to cycles.
In certain similar logic systems with notions of duplication, this is a point of failure for such a representation.

\begin{example}
In $\SELS$ \cite{strassburger2003mell}, a simpler system than $\sSys$ with no notion of sequencing, structures duplicated with the \textit{of course} structure $!R$ are placed inside of a par structure by the $\bU$ rule:

\[
\vlderivation{
    \vlin{\bU}{}{S(R,!R)}{
    \vlhy{S\{!R\}}
}}
\]

This allows us to construct the following derivation:

\[
\vlderivation{
    \vlin{\sw}{}{[(a,\overline{a}),a,\overline{a}]}{
    \vlin{\sw}{}{[(a,[a,\overline{a}]),\overline{a}]}{
    \vlin{\wU}{}{([a,\overline{a}],[a,\overline{a}])}{
    \vlin{\bU}{}{([a,\overline{a}],[a,\overline{a}],![a,\overline{a}])}{
    \vlin{\bU}{}{([a,\overline{a}],![a,\overline{a}])}{
    \vlhy{![a,\overline{a}]}
    }}}}}
}
\]

That is, we have a derivation from $S[a,\overline{a}]$ to $S'(a,\overline{a})$, where $S=!\{\quad\}$ and $S'=[\{\quad\},a,\overline{a}]$.
\end{example}

WIP:
\begin{definition}
For any application of a rewrite rule in $\sSys$, atoms in the conclusion are \textit{connected} in any of the following cases:
\begin{itemize}
    \item They are some pair $[a,\overline{a}]$ introduced by the rule $\aiD$
    \item 
\end{itemize}
\end{definition}

- Conclude that proofs are dinatural as they are compositions of naturals and dinaturals with no cycles
- Atomic flows????

\newpage
\section{Conclusion and Future Work}

\subsection{$\sSys$ and its Model}
We have shown the 

\subsection{Dinaturality of General Derivations}

\subsection{Consistency}
\textit{"There are several things we would like to have in addition.
On the semantics side, it would be good to show that every proof is interpreted as a non-empty relation.
One limitation of coherence space semantics is that every hom-set in the category has at least one element, the empty relation.
If we could show that every proof is a non-empty relation then I believe we could deduce that the logic is “consistent” i.e. there are some formulas that cannot be proved, because there are no non-empty natural transformations to serve as their interpretation.
(I'll try to come up with an example you could include.)
The way to prove this non-emptiness is to add a “totality” predicate to the coherence spaces and show that every proof takes total elements to total elements;
this is Loader’s totality spaces idea and I think it would be fine to throw in a conjecture that every proof is non-empty and say that this is how you would approach the proof."}

\subsection{Cut Elimination}


\newpage
\bibliographystyle{plain}
\bibliography{references}

\end{document}